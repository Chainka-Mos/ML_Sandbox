{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Портяная Линейная/Нелинейная регрессия.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMNEP6kKkZmQ4iu8W20LAH7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chainka-Mos/ML_Sandbox/blob/master/%D0%9F%D0%BE%D1%80%D1%82%D1%8F%D0%BD%D0%B0%D1%8F_%D0%9B%D0%B8%D0%BD%D0%B5%D0%B9%D0%BD%D0%B0%D1%8F_%D0%9D%D0%B5%D0%BB%D0%B8%D0%BD%D0%B5%D0%B9%D0%BD%D0%B0%D1%8F_%D1%80%D0%B5%D0%B3%D1%80%D0%B5%D1%81%D1%81%D0%B8%D1%8F.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8I-apChWm_bx"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from sklearn.linear_model import LinearRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVO0ygROoFuO"
      },
      "source": [
        "#Первым делом зададим данные. Т.к. свобода выбора полная и абсолютная, возьмем цены закрытия акций Лукойл за первые 15 дней января 2019-го года и цены марки Брент того же периода. \r\n",
        "#Пусть за вектор экзогенных переменных X будет цена нефти Брент, за вектор эндогенных будет цена акций Лукойл"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iyAOTdH3psSH",
        "outputId": "c1e0a6d2-e186-4259-af8c-10d67d564b81"
      },
      "source": [
        "Lukoil = [5070,5100,5200,5250,5300,5400,5310,5400,5300,5330,5300,5450,5150,5120,5140,5300,5215,5200,5120,4900,4700,5070,5100,5200,5250,5300,5400,5310,5400,5300,5330,5300,5450,5150,5120,5140,5300,5215,5200,5120,4900,4700]\r\n",
        "Brent = [54.8,55,56,56.2,56.8,57,56.5,56.7,56.2,56.25,56.1,56.65,55.8,55.5,55.6,55.7,55.9,55.1,57.2,55.1,55.1,54.8,55,56,56.2,56.8,57,56.5,56.7,56.2,56.25,56.1,56.65,55.8,55.5,55.6,55.7,55.9,55.1,57.2,55.1,55.1]\r\n",
        "data = {'Lukoil':Lukoil,'Brent':Brent}\r\n",
        "df = pd.DataFrame(data=data)\r\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Lukoil</th>\n",
              "      <th>Brent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5070</td>\n",
              "      <td>54.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5100</td>\n",
              "      <td>55.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5200</td>\n",
              "      <td>56.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5250</td>\n",
              "      <td>56.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5300</td>\n",
              "      <td>56.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5400</td>\n",
              "      <td>57.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>5310</td>\n",
              "      <td>56.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>5400</td>\n",
              "      <td>56.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>5300</td>\n",
              "      <td>56.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>5330</td>\n",
              "      <td>56.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>5300</td>\n",
              "      <td>56.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>5450</td>\n",
              "      <td>56.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>5150</td>\n",
              "      <td>55.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>5120</td>\n",
              "      <td>55.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>5140</td>\n",
              "      <td>55.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>5300</td>\n",
              "      <td>55.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>5215</td>\n",
              "      <td>55.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>5200</td>\n",
              "      <td>55.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>5120</td>\n",
              "      <td>57.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>4900</td>\n",
              "      <td>55.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>4700</td>\n",
              "      <td>55.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>5070</td>\n",
              "      <td>54.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>5100</td>\n",
              "      <td>55.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>5200</td>\n",
              "      <td>56.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>5250</td>\n",
              "      <td>56.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>5300</td>\n",
              "      <td>56.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>5400</td>\n",
              "      <td>57.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>5310</td>\n",
              "      <td>56.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>5400</td>\n",
              "      <td>56.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>5300</td>\n",
              "      <td>56.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>5330</td>\n",
              "      <td>56.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>5300</td>\n",
              "      <td>56.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>5450</td>\n",
              "      <td>56.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>5150</td>\n",
              "      <td>55.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>5120</td>\n",
              "      <td>55.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>5140</td>\n",
              "      <td>55.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>5300</td>\n",
              "      <td>55.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>5215</td>\n",
              "      <td>55.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>5200</td>\n",
              "      <td>55.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>5120</td>\n",
              "      <td>57.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>4900</td>\n",
              "      <td>55.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>4700</td>\n",
              "      <td>55.10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Lukoil  Brent\n",
              "0     5070  54.80\n",
              "1     5100  55.00\n",
              "2     5200  56.00\n",
              "3     5250  56.20\n",
              "4     5300  56.80\n",
              "5     5400  57.00\n",
              "6     5310  56.50\n",
              "7     5400  56.70\n",
              "8     5300  56.20\n",
              "9     5330  56.25\n",
              "10    5300  56.10\n",
              "11    5450  56.65\n",
              "12    5150  55.80\n",
              "13    5120  55.50\n",
              "14    5140  55.60\n",
              "15    5300  55.70\n",
              "16    5215  55.90\n",
              "17    5200  55.10\n",
              "18    5120  57.20\n",
              "19    4900  55.10\n",
              "20    4700  55.10\n",
              "21    5070  54.80\n",
              "22    5100  55.00\n",
              "23    5200  56.00\n",
              "24    5250  56.20\n",
              "25    5300  56.80\n",
              "26    5400  57.00\n",
              "27    5310  56.50\n",
              "28    5400  56.70\n",
              "29    5300  56.20\n",
              "30    5330  56.25\n",
              "31    5300  56.10\n",
              "32    5450  56.65\n",
              "33    5150  55.80\n",
              "34    5120  55.50\n",
              "35    5140  55.60\n",
              "36    5300  55.70\n",
              "37    5215  55.90\n",
              "38    5200  55.10\n",
              "39    5120  57.20\n",
              "40    4900  55.10\n",
              "41    4700  55.10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vA6xiPrbrrbf"
      },
      "source": [
        "#Далее построим кор. поле, или по-другому диаграмму рассеивания"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "AU4XJqNzr9Oh",
        "outputId": "e6be3643-f22c-4924-9870-a4301d682c74"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "plt.scatter((df['Lukoil']),(df['Brent']))#имеем вполне линейный, прямой характер связи!"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f19479c2e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAATZElEQVR4nO3de4xcZ3nH8e/TtUylKECCjUtiu7k0QYCsRNHGsdokxaGkiUGN02ssTNNCMaUOVS8SAhJVqHVFuDWlUgQykduUkAsFbKUkTewiAa3aOFlTkjghgGMM8YbG615o/orlzdM/5qw9Xs+sZ3Znds68+/1Iqz3zzjmzz5yz+/P4fd9zTmQmkqRy/dSgC5Ak9ZdBL0mFM+glqXAGvSQVzqCXpMItGnQBrSxZsiTPOeecQZchSUNjz549hzNzaavnahn055xzDmNjY4MuQ5KGRkT8sN1zdt1IUuEMekkqnEEvSYUz6CWpcAa9JBWulrNupFLdsuNJ7tn9HJOZjESw4bIVbFm/atBlqXAGvTRPbtnxJHc98qNjjyczjz027NVPdt1I8+Se3c911S71ikEvzZPJNvd+aNcu9YpBL82TkYiu2qVeMeilebLhshVdtUu94mCsNE+mBlyddaP5FnW8Z+zo6Gh6UTNJ6lxE7MnM0VbP2XUjSYUz6CWpcAa9JBXOoJekwhn0klQ4g16SCmfQS1LhDHpJKpxBL0mF6+gSCBFxAHgRmASOZuZoRNwHvL5a5dXA/2bmxS22vQb4NDAC3JGZt/aicEkalGG7gUw317pZm5mHpx5k5m9NLUfEp4CfTN8gIkaA24G3AgeBxyLi/sx8evYlS9LgDOMNZObcdRMRAfwmcE+Lp1cD+zJzf2YeAe4Frpvrz5SkQRnGG8h0GvQJ7IyIPRGxadpzVwAvZOb3W2x3NtD87g9WbSeJiE0RMRYRYxMTEx2WJUnzaxhvINNp0F+emZcA1wKbI+LKpuc20PrTfFcyc2tmjmbm6NKlS+f6cpLUF8N4A5mOgj4zx6vvh4DtNLpkiIhFwK8C97XZdBxovqvC8qpNkobSMN5A5pRBHxGnRcTpU8vA1cDe6ulfAp7JzINtNn8MuCAizo2IxcANwP1zL1uSBmPL+lVsXLPy2Cf4kQg2rllZ24FY6GzWzTJge2PMlUXA3Zn5UPXcDUzrtomIs2hMo1yXmUcj4ibgYRrTK7dl5lM9q16SBmDL+lW1DvbpvMOUJBXAO0xJ0gJm0EtS4Qx6SSqcQS9JhTPoJalwBr0kFc6gl6TCdXOZYknqu2G71vswMOgl1cYwXut9GNh1I6k2hvFa78PAoJdUG8N4rfdhYNBLqo1hvNb7MDDoJdXGMF7rfRg4GCupNqYGXJ1101tepliSCjDTZYr9RC9JXRq2uf4GvSR1YRjn+jsYK0ldGMa5/ga9JHVhGOf6G/SS1IVhnOtvH70kdWHDZStO6KNvbp+tfg/uGvSS1IVez/Wfj8Fd59FL0gCd/6EHW/bvj0Tw7EfXdfw6M82jt49ekgZoPgZ3DXpJGqD5GNw16CVpgObjQm4OxkrSAM3HhdwcjJWkAjgYK0kLmEEvSYUz6CWpcAa9JBWuo1k3EXEAeBGYBI5OdfhHxPuBzVX7A5n5gU63laRODNtNPuqom+mVazPz8NSDiFgLXAdclJkvRcRrO91WkjoxjDf5qKO5dN28D7g1M18CyMxDvSlJkhqG8SYfddRp0CewMyL2RMSmqu1C4IqI2B0R34iIS7vY9iQRsSkixiJibGJiovN3IKlYw3iTjzrqtOvm8swcr7pndkXEM9W2ZwJrgEuBL0bEeXnyGVgnbZuZ35z+AzJzK7AVGidMzfYNSSrHSETbKzuqcx19os/M8er7IWA7sBo4CHwlGx4FXgaWdLitJJ3SfFwHZiE4ZdBHxGkRcfrUMnA1sBfYAayt2i8EFgOHO9xWkk5py/pVbFyz8tgn+JEINq5Z6UBslzrpulkGbI/Gjl4E3J2ZD0XEYmBbROwFjgA3ZmZGxFnAHZm5rt22/Xgjksq0Zf0qg32OThn0mbkfuKhF+xFgY4v254F1M20rSZo/nhkrSYUz6CWpcAa9JBXOoJekwhn0klQ4g16SCmfQS1LhDHpJKpxBL0mFM+glqXAGvSQVrptbCUpS7XhP2VMz6CUNLe8p2xm7biQNLe8p2xmDXtLQ8p6ynTHoJQ2tdveO9Z6yJ7KPXtKc9HowtJvX23DZihP66JvbdZxBL2nWej0Y2u3rTbU562ZmkTXsyxodHc2xsbFBlyHpFM7/0IMt+8NHInj2o+sG/noLSUTsyczRVs/ZRy9p1no9GOrgan8Y9JJmrdeDoQ6u9odBL2nW2g16znYwtNevpwYHYyXNWq8HQx1c7Q8HYyWpADMNxvqJXlKteJGy3jPoJdWGFynrDwdjJdWGFynrD4NeUm04j74/DHpJteE8+v4w6CXVhvPo+8PBWEm14Tz6/nAevSQVYM7z6CPiAPAiMAkcnXqxiHg/sLlqfyAzP9Bi22uATwMjwB2Zeets3oSk3nCe+sLTTdfN2sw8PPUgItYC1wEXZeZLEfHa6RtExAhwO/BW4CDwWETcn5lPz7FuSbPgPPWFaS6Dse8Dbs3MlwAy81CLdVYD+zJzf2YeAe6l8Y+DpAFwnvrC1GnQJ7AzIvZExKaq7ULgiojYHRHfiIhLW2x3NtD8G3SwajtJRGyKiLGIGJuYmOi0fkldcJ76wtRp183lmTledc/siohnqm3PBNYAlwJfjIjzcpaju5m5FdgKjcHY2byGpJmNRLS9g5PK1dEn+swcr74fArbT6JI5CHwlGx4FXgaWTNt0HGieALu8apM0AM5TX5hOGfQRcVpEnD61DFwN7AV2AGur9guBxcDhaZs/BlwQEedGxGLgBuD+3pUvqRtb1q9i45qVxz7Bj0Swcc1KB2IL10nXzTJgezR+MRYBd2fmQ1Vwb4uIvcAR4MbMzIg4i8Y0ynWZeTQibgIepjG9cltmPtWftyKpE1vWrzLYFxhPmJIEOL9+2HnjEUkzcn592byomSTn1xfOoJfk/PrCGfSSvA584Qx6Sc6vL5yDsZK8DnzhnF4pSQWYaXqlXTeSVDi7bqQa8yQm9YJBL9WUJzGpV+y6kWrKk5jUKwa9VFOexKReMeilmvIkJvWKQS/VlCcxqVccjJVqypOY1CueMCVJBfB69JKGhucO9J5BL6k2PHegPxyMlVQbnjvQHwa9pNrw3IH+MOgl1YbnDvSHQS+pNjx3oD8cjJVUG5470B/Oo5ekAjiPXhoSziFXPxj0Uk04h1z94mCsVBPOIVe/GPRSTTiHXP1i0Es14Rxy9YtBL9WEc8jVLw7GSjXhHHL1i/PoJakAc55HHxEHgBeBSeBoZo5GxEeA9wAT1WofzswHO9m22zcglcJ58hqEbrpu1mbm4Wltt2XmJ2e5rbSgOE9eg+JgrDRPnCevQek06BPYGRF7ImJTU/tNEfFERGyLiDO63PYEEbEpIsYiYmxiYqLdatLQcp68BqXToL88My8BrgU2R8SVwGeA84GLgR8Dn+pi25Nk5tbMHM3M0aVLl3b1JqRh4Dx5DUpHQZ+Z49X3Q8B2YHVmvpCZk5n5MvA5YHWn2/aicGnYOE9eg3LKoI+I0yLi9Kll4Gpgb0S8rmm164G9nW7bi8KlYbNl/So2rll57BP8SAQb16x0IFZ918msm2XA9mj8ci4C7s7MhyLi8xFxMY0++APAewEi4izgjsxc127bnr8LaUhsWb/KYNe8O2XQZ+Z+4KIW7e9ss/7zwLqZtpUkzR+nV0pS4Qx6SSqcQS9JhTPoJalwBr0kFc6gl6TCGfSSVDiDXpIKZ9BLUuEMekkqnEEvSYUz6CWpcAa9JBXOoJekwhn0klQ4g16SCmfQS1LhDHpJKpxBL0mFM+glqXAGvSQVzqCXpMIZ9JJUOINekgq3aNAF9MotO57knt3PMZnJSAQbLlvBlvWrBl3WUHEfLgwe54WniKC/ZceT3PXIj449nsw89thf4M64DxcGj/PCVETXzT27n+uqXSdzHy4MHueFqYign8zsql0ncx8uDB7nhamIoB+J6KpdJ3MfLgwe54WpiKDfcNmKrtp1MvfhwuBxXpiKGIydGkRyJsHsuQ8XBo/zwhRZw7650dHRHBsbG3QZkjQ0ImJPZo62eq6jT/QRcQB4EZgEjmbmaER8BHgPMFGt9uHMfLDFttcAnwZGgDsy89au34E0JJyjrjrqputmbWYentZ2W2Z+st0GETEC3A68FTgIPBYR92fm092XKtWbc9RVV/0ejF0N7MvM/Zl5BLgXuK7PP1MaCOeoq646DfoEdkbEnojY1NR+U0Q8ERHbIuKMFtudDTT/lh+s2k4SEZsiYiwixiYmJlqtItWac9RVV50G/eWZeQlwLbA5Iq4EPgOcD1wM/Bj41FwKycytmTmamaNLly6dy0tJA+EcddVVR0GfmePV90PAdmB1Zr6QmZOZ+TLwORrdNNONA80TdJdXbVJxnKOuujpl0EfEaRFx+tQycDWwNyJe17Ta9cDeFps/BlwQEedGxGLgBuD+uZct1c+W9avYuGblsU/wIxFsXLPSgVgNXCezbpYB26Pxy7sIuDszH4qIz0fExTT67w8A7wWIiLNoTKNcl5lHI+Im4GEa0yu3ZeZTfXgfUi1sWb/KYFfteMKUJBVgphOmirjWjSSpPYNekgpn0EtS4Qx6SSqcQS9JhTPoJalwBr0kFc6gl6TCFXErQalfvJGISmDQS214IxGVwq4bqQ1vJKJSGPRSG95IRKUw6KU2vJGISmHQS214IxGVwsFYqY2pAVdn3WjYeT16SSqA16OXpAXMoJekwhn0klQ4g16SCmfQS1LhajnrJiImgB/OcvMlwOEeltNrda8PrLEX6l4f1L/GutcH9arxZzNzaasnahn0cxERY+2mGNVB3esDa+yFutcH9a+x7vXBcNQIdt1IUvEMekkqXIlBv3XQBZxC3esDa+yFutcH9a+x7vXBcNRYXh+9JOlEJX6ilyQ1MeglqXBDE/QRMRIR/xERX60e/0tEfLv6ej4idlTtERF/ExH7IuKJiLik6TVujIjvV1839rm+t0TEt6r6/jUifq5qf0VE3FfVtzsizml6jQ9V7d+NiF/uZX1taryqqnFvRNwZEYuq9kHtwwMR8WS1z8aqtjMjYlf183ZFxBmDqrFNfb8REU9FxMsRMTpt/ZbHMyKuqdr2RcQHe1XfDDV+IiKeqfbT9oh4dQ1r/Iuqvm9HxM6IOKtqr8VxbnruTyMiI2LJoOqblcwcii/gT4C7ga+2eO7LwG9Xy+uAfwICWAPsrtrPBPZX38+ols/oV33A94A3VMt/APxd0/Jnq+UbgPuq5TcCjwOvAM4FngVG+rUPafwj/xxwYfXcnwPvHvA+PAAsmdb2ceCD1fIHgY8NqsY29b0BeD3wdWC0qb3l8ay+ngXOAxZX67yxz/vwamBRtfyxpn1Ypxpf2bT8h01/I7U4zlX7CuBhGidzLhnk30q3X0PxiT4ilgNvA+5o8dwrgauAHVXTdcDfZ8MjwKsj4nXALwO7MvO/M/N/gF3ANX2sL4FXVsuvAp5vqu/OavlLwFsiIqr2ezPzpcz8AbAPWN2L+trU+BrgSGZ+r3q8C/i1phrndR/OoHl/3Qmsr1ONmfmdzPxum7pbHc/VwL7M3J+ZR4B7q3X7JjN3ZubR6uEjwPIa1vh/TQ9Po/H3M1XjwI9z5TbgA0211a2+toYi6IG/prGDX27x3Hrga02/KGfT+KQ65WDV1q69X/X9HvBgRBwE3gncOr2+6o/vJzRCt5/1tarxMLCoqbvh12l8Yjmhxmm19LvGBHZGxJ6I2FS1LcvMH1fL/wksG2CNreprp077sNm7aHwCrV2NEfGXEfEc8A7gzwZY40n1RcR1wHhmPj5t3UHtw67UPugj4u3Aoczc02aVDcA981jSCWao74+BdZm5HPhb4K/mvbhKqxqz8f/LG4DbIuJR4EVgckAlTrk8My8BrgU2R8SVzU9WNQ9yPvCM9dVE2xoj4mbgKPCFQRVXaVljZt6cmSto1HdTzer7MMf/8Rk6tQ964BeAX4mIAzT+C3lVRNwFUA2IrAYeaFp/nOOfTKHx39TxGdr7Ud8DwEWZubta5z7g56fXF43Bz1cB/9XH+trVeFdm/ntmXpGZq4Fv0hhXOKHGabX0s0Yyc7z6fgjYTuPYvlD9V5jq+6FB1dimvnbqtA+JiN8B3g68o/oHs3Y1NvkCx7sR63Ccf5HGGMbj1d/QcuBbEfEzg6hvVgY1ODCbL+DNNA3GAr8P3Dltnbdx4uDIo3l8cOQHNAZGzqiWz+xHfTRuun6Y4wOd7wa+XC1v5sTB2C9Wy2/ixIGx/fR4MHb6PgReW31/BfA14KpB7UMa/bKnNy3/G40+zU9w4mDsxwdRY7v6mp7/OicOxrY8ntXvxv6qbWqg80193ofXAE8DS6etX6caL2ha5/3Al+p4nKv2AxwfjB1Y3nT1vgb1g2d5EN7MiUH/9RYHIYDbacwaeHLaH9+7aAw47QN+t5/1AddXP//xqs7zqvafBv6hquHRqfbquZurur8LXNvvfUgjRL9T/bw/GuQ+pDHD4/Hq6yng5qr9NTT+Efo+8M9TfyzzXeMM9V1Po//1JeAF4OFTHU8aMzW+Vz138zzsw300+ou/XX19toY1fhnYCzwB/CNwdp2O87R1DnA86AeWN918eQkESSrcMPTRS5LmwKCXpMIZ9JJUOINekgpn0EtS4Qx6SSqcQS9Jhft/18LzP4hLDmgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "wOrdsnP9xymM",
        "outputId": "4c9f2af5-4244-419b-e819-0740f90ee261"
      },
      "source": [
        "#Также проверим на кор.связи\r\n",
        "import seaborn as sns\r\n",
        "sns.heatmap(df.corr(),annot = True)# связь почти под единичку, по шкале Чеддока это говорит о наличии сильной и устойчивой связи что хорошо для предиктивной модели"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f195b1adb38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcuJ9bCMwmIW"
      },
      "source": [
        "#Далее для подбора наиболее оптимального коэффициента воспользуемся встроенными библиотеками, которые базируются на обычном МНК. Конечно, применение именно МНК необходимо обосновывать как минимум \r\n",
        "#проверкой постулатов теоремы Гаусса-Маркова, но т.к. в задании это явно сказано не было, то мы не станем усложнять себе жизнь и просто построим уравнение парной регрессии."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4iuYEynxQoT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "outputId": "6a747275-724e-4533-87dc-1723781034c4"
      },
      "source": [
        "#Линейная регрессия с предварительной кросс-валидацией и обязательным разбитием на тренировочную и тестовую выборки в формате 80% на 20%\r\n",
        "from sklearn.linear_model import LinearRegression\r\n",
        "from sklearn.metrics import mean_squared_error, r2_score\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import statsmodels.api as sm\r\n",
        "Xtrn, Xtest, Ytrn, Ytest = train_test_split(df['Brent'],df['Lukoil'], test_size=0.2)\r\n",
        "gls = sm.OLS(Ytrn, Xtrn)\r\n",
        "gls_result = gls.fit()\r\n",
        "gls_result.summary() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>         <td>Lukoil</td>      <th>  R-squared (uncentered):</th>      <td>   0.999</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.999</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>5.816e+04</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Fri, 22 Jan 2021</td> <th>  Prob (F-statistic):</th>          <td>9.78e-54</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>16:16:45</td>     <th>  Log-Likelihood:    </th>          <td> -205.47</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>    33</td>      <th>  AIC:               </th>          <td>   412.9</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>    32</td>      <th>  BIC:               </th>          <td>   414.4</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>              <td> </td>    \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>    \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Brent</th> <td>   93.2382</td> <td>    0.387</td> <td>  241.169</td> <td> 0.000</td> <td>   92.451</td> <td>   94.026</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>21.784</td> <th>  Durbin-Watson:     </th> <td>   2.172</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  31.466</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td>-1.744</td> <th>  Prob(JB):          </th> <td>1.47e-07</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 6.274</td> <th>  Cond. No.          </th> <td>    1.00</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                                 OLS Regression Results                                \n",
              "=======================================================================================\n",
              "Dep. Variable:                 Lukoil   R-squared (uncentered):                   0.999\n",
              "Model:                            OLS   Adj. R-squared (uncentered):              0.999\n",
              "Method:                 Least Squares   F-statistic:                          5.816e+04\n",
              "Date:                Fri, 22 Jan 2021   Prob (F-statistic):                    9.78e-54\n",
              "Time:                        16:16:45   Log-Likelihood:                         -205.47\n",
              "No. Observations:                  33   AIC:                                      412.9\n",
              "Df Residuals:                      32   BIC:                                      414.4\n",
              "Df Model:                           1                                                  \n",
              "Covariance Type:            nonrobust                                                  \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "Brent         93.2382      0.387    241.169      0.000      92.451      94.026\n",
              "==============================================================================\n",
              "Omnibus:                       21.784   Durbin-Watson:                   2.172\n",
              "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               31.466\n",
              "Skew:                          -1.744   Prob(JB):                     1.47e-07\n",
              "Kurtosis:                       6.274   Cond. No.                         1.00\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctgByhKE3yOn"
      },
      "source": [
        "#Что же мы имеем в таком случае? При правильно подобранных коэффициентах a0 и a1, где для уравнения вида y = a0*x+a1+e(где a1, правда, равен 0) коэф. a0 - предельные изменения y при изменении x на 1 единицу,\r\n",
        "# а a1 - коэффициент смещения, который покрывает постоянную разницу между y и x, коэффициент детерминации, даже смещенный на кол-во регрессоров демонстрирует великолепные 0.99, практически функциональную зависимость.\r\n",
        "# Статистическую гипотезу о достоверности выбранного уравнения регрессии можно сделать при помощи F-теста, где при альфа \r\n",
        "# на уровне 0.05 имеем Fконтрольное = 12.7, т.е. Ftest<Fконтр и уравнение признается значимым. Попутно мы также можем заявить, что выполняется первый постулат теоремы Г-М. Значимость экз. переменных\r\n",
        "# можно проверить при помощи T-теста, что также представлено в сводной таблице выше. При 0.975 имеем 93.955 => наш единственный регрессор значимый."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VS3kqhrJ5Yl6",
        "outputId": "bf4e76f0-e175-43bd-c539-d103f5d7a0e7"
      },
      "source": [
        "# Финальный пункт - средн.относит.ошибка\r\n",
        "from sklearn.metrics import mean_absolute_error\r\n",
        "y_predicted = gls_result.predict(Xtest)\r\n",
        "mape = mean_absolute_error(Ytest, y_predicted) / Ytest.abs().sum()\r\n",
        "mape\r\n",
        "#величина по сравнению с нашим Y, который различается день от дня обычно на величины 0.2 и выше, небольшая. Полученное уравнение регресси Y = 93.13X + e может быть использовано как предиктивное."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0023525731184589832"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "YrpSQ-JH7UIB",
        "outputId": "f5467924-ceec-4bea-8066-863d2b92c056"
      },
      "source": [
        "#Перейдем к задаче 2. Начнем с лог.модели, т.е. изменим x на lnx. По-идеи это должно помочь нам справиться с выбросами, которые были заметны на графике.\r\n",
        "data = {'Lukoil':Lukoil,'Brent':np.log(Brent)}\r\n",
        "df = pd.DataFrame(data=data)\r\n",
        "plt.scatter((df['Lukoil']),(df['Brent']))#фактически, не изменилось ничего..."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f19478ec320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKJo_uSv8X0u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "outputId": "44e425c9-78cf-4105-d362-8a3c4dc0cd7c"
      },
      "source": [
        "##неЛинейная ln-регрессия с предварительной кросс-валидацией и обязательным разбитием на тренировочную и тестовую выборки в формате 80% на 20%\r\n",
        "Xtrn, Xtest, Ytrn, Ytest = train_test_split(df['Brent'],df['Lukoil'], test_size=0.2)\r\n",
        "gls = sm.OLS(Ytrn, Xtrn)\r\n",
        "gls_result = gls.fit()\r\n",
        "gls_result.summary() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>         <td>Lukoil</td>      <th>  R-squared (uncentered):</th>      <td>   0.999</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.999</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>4.478e+04</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Fri, 22 Jan 2021</td> <th>  Prob (F-statistic):</th>          <td>6.40e-52</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>16:24:39</td>     <th>  Log-Likelihood:    </th>          <td> -209.86</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>    33</td>      <th>  AIC:               </th>          <td>   421.7</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>    32</td>      <th>  BIC:               </th>          <td>   423.2</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>              <td> </td>    \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>    \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Brent</th> <td> 1299.1243</td> <td>    6.139</td> <td>  211.610</td> <td> 0.000</td> <td> 1286.619</td> <td> 1311.630</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>19.840</td> <th>  Durbin-Watson:     </th> <td>   1.948</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  29.500</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td>-1.514</td> <th>  Prob(JB):          </th> <td>3.93e-07</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 6.505</td> <th>  Cond. No.          </th> <td>    1.00</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                                 OLS Regression Results                                \n",
              "=======================================================================================\n",
              "Dep. Variable:                 Lukoil   R-squared (uncentered):                   0.999\n",
              "Model:                            OLS   Adj. R-squared (uncentered):              0.999\n",
              "Method:                 Least Squares   F-statistic:                          4.478e+04\n",
              "Date:                Fri, 22 Jan 2021   Prob (F-statistic):                    6.40e-52\n",
              "Time:                        16:24:39   Log-Likelihood:                         -209.86\n",
              "No. Observations:                  33   AIC:                                      421.7\n",
              "Df Residuals:                      32   BIC:                                      423.2\n",
              "Df Model:                           1                                                  \n",
              "Covariance Type:            nonrobust                                                  \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "Brent       1299.1243      6.139    211.610      0.000    1286.619    1311.630\n",
              "==============================================================================\n",
              "Omnibus:                       19.840   Durbin-Watson:                   1.948\n",
              "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               29.500\n",
              "Skew:                          -1.514   Prob(JB):                     3.93e-07\n",
              "Kurtosis:                       6.505   Cond. No.                         1.00\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "P2y3kg1j9B0N",
        "outputId": "913ea05b-818a-4a11-c78a-b9ff94bf06d7"
      },
      "source": [
        "#гиперболич. модель\r\n",
        "data = {'Lukoil':Lukoil,'Brent':Brent}\r\n",
        "df = pd.DataFrame(data=data)\r\n",
        "df['Brent'] = df['Brent']*0.1\r\n",
        "##неЛинейная гипербол-регрессия с предварительной кросс-валидацией и обязательным разбитием на тренировочную и тестовую выборки в формате 80% на 20%\r\n",
        "Xtrn, Xtest, Ytrn, Ytest = train_test_split(df['Brent'],df['Lukoil'], test_size=0.2)\r\n",
        "gls = sm.OLS(Ytrn, Xtrn)\r\n",
        "gls_result = gls.fit()\r\n",
        "gls_result.summary() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>         <td>Lukoil</td>      <th>  R-squared (uncentered):</th>      <td>   0.999</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.999</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>4.263e+04</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Fri, 22 Jan 2021</td> <th>  Prob (F-statistic):</th>          <td>1.40e-51</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>16:29:47</td>     <th>  Log-Likelihood:    </th>          <td> -210.29</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>    33</td>      <th>  AIC:               </th>          <td>   422.6</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>    32</td>      <th>  BIC:               </th>          <td>   424.1</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>              <td> </td>    \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>    \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Brent</th> <td>  925.4084</td> <td>    4.482</td> <td>  206.478</td> <td> 0.000</td> <td>  916.279</td> <td>  934.538</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>12.750</td> <th>  Durbin-Watson:     </th> <td>   2.378</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.002</td> <th>  Jarque-Bera (JB):  </th> <td>  12.447</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td>-1.283</td> <th>  Prob(JB):          </th> <td> 0.00198</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 4.570</td> <th>  Cond. No.          </th> <td>    1.00</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                                 OLS Regression Results                                \n",
              "=======================================================================================\n",
              "Dep. Variable:                 Lukoil   R-squared (uncentered):                   0.999\n",
              "Model:                            OLS   Adj. R-squared (uncentered):              0.999\n",
              "Method:                 Least Squares   F-statistic:                          4.263e+04\n",
              "Date:                Fri, 22 Jan 2021   Prob (F-statistic):                    1.40e-51\n",
              "Time:                        16:29:47   Log-Likelihood:                         -210.29\n",
              "No. Observations:                  33   AIC:                                      422.6\n",
              "Df Residuals:                      32   BIC:                                      424.1\n",
              "Df Model:                           1                                                  \n",
              "Covariance Type:            nonrobust                                                  \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "Brent        925.4084      4.482    206.478      0.000     916.279     934.538\n",
              "==============================================================================\n",
              "Omnibus:                       12.750   Durbin-Watson:                   2.378\n",
              "Prob(Omnibus):                  0.002   Jarque-Bera (JB):               12.447\n",
              "Skew:                          -1.283   Prob(JB):                      0.00198\n",
              "Kurtosis:                       4.570   Cond. No.                         1.00\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "96bqFbt5-NH4",
        "outputId": "feb53399-a7b2-4399-b71d-c5f78571d33c"
      },
      "source": [
        "#степенная модель\r\n",
        "data = {'Lukoil':Lukoil,'Brent':Brent}\r\n",
        "df = pd.DataFrame(data=data)\r\n",
        "df['Brent'] = np.log(df['Brent'])\r\n",
        "df['Lukoil'] = np.log(df['Lukoil'])\r\n",
        "##неЛинейная гипербол-регрессия с предварительной кросс-валидацией и обязательным разбитием на тренировочную и тестовую выборки в формате 80% на 20%\r\n",
        "from sklearn.linear_model import LinearRegression\r\n",
        "from sklearn.metrics import mean_squared_error, r2_score\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import statsmodels.api as sm\r\n",
        "Xtrn, Xtest, Ytrn, Ytest = train_test_split(df['Brent'],df['Lukoil'], test_size=0.2)\r\n",
        "gls = sm.OLS(Ytrn, Xtrn)\r\n",
        "gls_result = gls.fit()\r\n",
        "gls_result.summary() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>         <td>Lukoil</td>      <th>  R-squared (uncentered):</th>      <td>   1.000</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   1.000</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>3.489e+06</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Fri, 22 Jan 2021</td> <th>  Prob (F-statistic):</th>          <td>3.50e-82</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>16:31:42</td>     <th>  Log-Likelihood:    </th>          <td>  73.722</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>    33</td>      <th>  AIC:               </th>          <td>  -145.4</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>    32</td>      <th>  BIC:               </th>          <td>  -143.9</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>              <td> </td>    \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>    \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Brent</th> <td>    2.1253</td> <td>    0.001</td> <td> 1867.951</td> <td> 0.000</td> <td>    2.123</td> <td>    2.128</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>14.622</td> <th>  Durbin-Watson:     </th> <td>   1.503</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  15.107</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td>-1.496</td> <th>  Prob(JB):          </th> <td>0.000524</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 4.428</td> <th>  Cond. No.          </th> <td>    1.00</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                                 OLS Regression Results                                \n",
              "=======================================================================================\n",
              "Dep. Variable:                 Lukoil   R-squared (uncentered):                   1.000\n",
              "Model:                            OLS   Adj. R-squared (uncentered):              1.000\n",
              "Method:                 Least Squares   F-statistic:                          3.489e+06\n",
              "Date:                Fri, 22 Jan 2021   Prob (F-statistic):                    3.50e-82\n",
              "Time:                        16:31:42   Log-Likelihood:                          73.722\n",
              "No. Observations:                  33   AIC:                                     -145.4\n",
              "Df Residuals:                      32   BIC:                                     -143.9\n",
              "Df Model:                           1                                                  \n",
              "Covariance Type:            nonrobust                                                  \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "Brent          2.1253      0.001   1867.951      0.000       2.123       2.128\n",
              "==============================================================================\n",
              "Omnibus:                       14.622   Durbin-Watson:                   1.503\n",
              "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               15.107\n",
              "Skew:                          -1.496   Prob(JB):                     0.000524\n",
              "Kurtosis:                       4.428   Cond. No.                         1.00\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anYeP6Q--_zL",
        "outputId": "668085bc-de47-4763-c074-21d9a4004237"
      },
      "source": [
        "y_predicted = gls_result.predict(Xtest)\r\n",
        "mape = mean_absolute_error(Ytest, y_predicted) / Ytest.abs().sum()\r\n",
        "mape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.00023584616070910532"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsYkbMXK-o8v"
      },
      "source": [
        "#Разве что на последней из моделей, степенной, получаем фактически функциональную связь(R^2 = 1), прекрасную F и T статистики и еще более маленькую ошибку аппроксимации.\r\n",
        "# Стоит отметить, что во всех случаях такие высокие показатели были обусловлены во-первых искусственностью данных, во-вторых малым объемом выборки, а в последнем случае к тому же залогорифмированностью\r\n",
        "#всех показателей. При обратном переходе к нелин.модели с большой вероятностью результаты сравняются с другими моделями.\r\n",
        "#Подытоживая оба задания можно смело заявлять, что с эконометрической точки зрения зависимость y от x(Лукойл и брент) является сильной линейной, и парной регресси тут будет абсолюнто достаточно."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}